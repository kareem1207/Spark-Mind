{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16eb1aed-a065-4a02-9129-8369852f092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0+cpu CUDA: False\n",
      "ffmpeg on PATH: True\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, torch, whisper as ws\n",
    "from typing import Any\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
    "print(\"ffmpeg on PATH:\", bool(shutil.which(\"ffmpeg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio exists: True\n"
     ]
    }
   ],
   "source": [
    "import json as js\n",
    "audio_path = r\"d:\\Early Spark\\backend\\audio\\audio2.mp3\"\n",
    "print(\"Audio exists:\", os.path.exists(audio_path))\n",
    "\n",
    "model: Any = ws.load_model(\"small\", device=\"cpu\", download_root=r\"D:\\Models\\whisper_cache\")\n",
    "result: dict = model.transcribe(audio_path, fp16=False, language=\"en\", word_timestamps=True)\n",
    "with open(\"transcription.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    js.dump(result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed68070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 18.8\n",
      "Total pause time: 16.360000000000003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open(\"transcription.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "\ttext = js.load(f)\n",
    "\n",
    "total_time:float = -0.0\n",
    "total_pause_time:float = 0.0\n",
    "for segment in text[\"segments\"]:\n",
    "    total_time = max(total_time, segment[\"end\"])\n",
    "    if(np.abs(segment[\"start\"] - segment[\"end\"])>0.8 ):\n",
    "        total_pause_time += np.abs(segment[\"start\"] - segment[\"end\"])\n",
    "print(\"Total time:\", total_time)\n",
    "print(\"Total pause time:\", total_pause_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066fa78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause density (%): 46.5301\n"
     ]
    }
   ],
   "source": [
    "pause_density : float = np.round(total_pause_time / (total_pause_time + total_time) * 100,4)\n",
    "print(\"Pause density (%):\", pause_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58b41cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 1,\n",
       " 'you': 2,\n",
       " 'woke': 1,\n",
       " 'up': 1,\n",
       " 'late': 1,\n",
       " 'today': 1,\n",
       " 'um': 1,\n",
       " 'then': 1,\n",
       " 'i': 5,\n",
       " 'went': 1,\n",
       " 'to': 1,\n",
       " 'the': 5,\n",
       " 'kitchen': 1,\n",
       " 'and': 3,\n",
       " 'uh': 1,\n",
       " 'made': 1,\n",
       " 'tea': 1,\n",
       " 'sat': 2,\n",
       " 'down': 2,\n",
       " 'in': 1,\n",
       " 'chair': 1,\n",
       " 'just': 1,\n",
       " 'stared': 1,\n",
       " 'at': 1,\n",
       " 'clock': 1,\n",
       " 'know': 1,\n",
       " 'was': 1,\n",
       " 'thinking': 1,\n",
       " 'about': 1,\n",
       " 'river': 2,\n",
       " 'near': 1,\n",
       " 'my': 1,\n",
       " 'old': 1,\n",
       " 'house': 1,\n",
       " 'mango': 1,\n",
       " 'trees': 1,\n",
       " 'paper': 1,\n",
       " 'boats': 1,\n",
       " 'it': 1,\n",
       " 's': 1,\n",
       " 'a': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count: dict[str, int] = {}\n",
    "\n",
    "new_text:str = text[\"text\"].replace(\"\\n\", \" \").replace(\".\", \" \").replace(\",\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\";\", \" \").replace(\":\", \" \").replace(\"\\\"\", \" \").replace(\"'\", \" \").replace(\"(\", \" \").replace(\")\", \" \").replace(\"[\", \" \").replace(\"]\", \" \").replace(\"{\", \" \").replace(\"}\", \" \").replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "\n",
    "for word in new_text.split():\n",
    "    words_count[word.lower()] = words_count.get(word.lower(), 0) + 1\n",
    "\n",
    "words_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed1a6dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated words: 14\n"
     ]
    }
   ],
   "source": [
    "repeated_words:int =0\n",
    "for i in words_count:\n",
    "    if words_count[i] > 1:\n",
    "        repeated_words += words_count.get(i,0)-1\n",
    "print(\"Repeated words:\", repeated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9eff7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filler words: 5\n",
      "Filler frequency: 9.0909\n"
     ]
    }
   ],
   "source": [
    "filler_Count :int =0\n",
    "for i in [\"um\",\"uh\",\"like\",\"you know\",\"so\",\"actually\",\"basically\",\"right\",\"i mean\",\"and\",\"but\",\"or\"]:\n",
    "    filler_Count += words_count.get(i,0)\n",
    "\n",
    "filler_frequency : float = np.round(filler_Count / np.sum(list(words_count.values())) * 100,4)\n",
    "print(\"Filler words:\", filler_Count)\n",
    "print(\"Filler frequency:\", filler_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "782b799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 34\n"
     ]
    }
   ],
   "source": [
    "unique_words:int =0\n",
    "for i in words_count:\n",
    "    if words_count[i] ==1:\n",
    "        unique_words += 1\n",
    "print(\"Unique words:\", unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60f76a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical diversity (%): 61.8182\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity : float = np.round(unique_words / np.sum(list(words_count.values())) * 100,4)\n",
    "print(\"Lexical diversity (%):\", lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e77de8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech fluency (words/sec): 56.17\n"
     ]
    }
   ],
   "source": [
    "speech_fluency : float = np.round(100 - (pause_density * 0.6) - (filler_frequency * 0.8) - (repeated_words * 1.5) + (lexical_diversity * 0.2), 2)\n",
    "print(\"Speech fluency (words/sec):\", speech_fluency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1e68e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rest :dict[str,float] = {\n",
    "    \"Total time\": total_time,\n",
    "    \"Total pause time\": total_pause_time,\n",
    "    \"Pause density (%)\": pause_density,\n",
    "    \"Repeated words\": repeated_words,\n",
    "    \"Filler words\": filler_Count,\n",
    "    \"Filler frequency (%)\": filler_frequency,\n",
    "    \"Unique words\": unique_words,\n",
    "    \"Lexical diversity (%)\": lexical_diversity,\n",
    "    \"Speech fluency (words/sec)\": speech_fluency\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840a23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SparkMind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
